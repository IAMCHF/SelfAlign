/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 4 --select_subtomo_number 90 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 1000 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/_93]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_74]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_17540]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 1000 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_2/ReadVariableOp/_60]]
	 [[update_0/AssignAddVariableOp/_105]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_2/ReadVariableOp/_60]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_17540]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[update_0_49/AssignAddVariableOp/_177]]
	 [[div_no_nan_1/ReadVariableOp_2/_148]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[update_0_49/AssignAddVariableOp/_177]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15147]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
	 [[update_0_48/AssignAddVariableOp/_193]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15147]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 100 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1824, in run_step
      outputs = model.test_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1790, in test_step
      self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_74]]
	 [[update_0/AssignAddVariableOp/_105]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_74]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_16520]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 8 --select_subtomo_number 10 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --batch_size 16 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 46, in run
    check_gpu(args)
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 223, in check_gpu
    raise RuntimeError('Re-enter correct gpuID')
RuntimeError: Re-enter correct gpuID
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, batch_size=batch_size,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_3/_150]]
	 [[div_no_nan_1/_165]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_3/_150]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15147]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp/_144]]
	 [[update_0_48/AssignAddVariableOp/_193]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp/_144]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15147]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan/ReadVariableOp_3/_162]]
	 [[update_0_49/AssignAddVariableOp/_177]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan/ReadVariableOp_3/_162]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15147]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 14, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_3/_150]]
	 [[update_0_48/AssignAddVariableOp/_193]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_3/_150]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15168]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
	 [[update_0_48/AssignAddVariableOp/_193]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15124]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      error = tf.norm(y_true - y_pred, axis=-1)
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      error = tf.norm(y_true - y_pred, axis=-1)
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 16, in translation_loss
      error = tf.norm(y_true - y_pred, axis=-1)
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan/ReadVariableOp/_152]]
	 [[div_no_nan_1/_165]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan/ReadVariableOp/_152]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15332]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 12, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 12, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 12, in translation_loss
      return tf.reduce_mean(tf.abs(y_true - y_pred))
Node: 'translation_loss/sub'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
	 [[update_0_48/AssignAddVariableOp/_193]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp_1/_146]]
  (2) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15124]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 32 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 2 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 4 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in train_pcrnet
    history = train_pcrnet_continue(
  File "/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'replica_1/model/conv3d_7/Conv3D' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'replica_1/model/conv3d_7/Conv3D'
Detected at node 'replica_1/model/conv3d_7/Conv3D' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'replica_1/model/conv3d_7/Conv3D'
Detected at node 'replica_1/model/conv3d_7/Conv3D' defined at (most recent call last):
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/ubuntu/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'replica_1/model/conv3d_7/Conv3D'
3 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,94,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc
	 [[{{node replica_1/model/conv3d_7/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp_2/_148]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[update_1_49/AssignAddVariableOp/_173]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,94,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc
	 [[{{node replica_1/model/conv3d_7/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp_2/_148]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (2) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,94,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc
	 [[{{node replica_1/model/conv3d_7/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_15124]
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 1024 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 2 --select_subtomo_number 512 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota --preprocessing_ncpus 22
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 128 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota --preprocessing_ncpus 22
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 200 --gpuID 0,1 --batch_size 16 --select_subtomo_number 500 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota --preprocessing_ncpus 22
/newdata/SW.HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 50 --gpuID 0,1 --batch_size 64 --select_subtomo_number 1024 --result_dir /newdata/SW.HBV/Caohaofan/results --rota /newdata/SW.HBV/Caohaofan/rota --preprocessing_ncpus 22
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 48, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 60, in get_model
    source_features = multi_scale_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 43, in multi_scale_feature_extractor
    net = Concatenate(axis=-1)([net_2_pool, net_3_pool, net_5_pool, net_7_pool])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/merging/concatenate.py", line 131, in build
    raise ValueError(err_msg)
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 24, 24, 24, 64), (None, 24, 24, 24, 64), (None, 23, 23, 23, 64), (None, 22, 22, 22, 64)]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 48, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 61, in get_model
    source_features = multi_scale_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 44, in multi_scale_feature_extractor
    net = Concatenate(axis=-1)([net_2_pool, net_3_pool, net_5_pool, net_7_pool])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/merging/concatenate.py", line 131, in build
    raise ValueError(err_msg)
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 24, 24, 24, 64), (None, 24, 24, 24, 64), (None, 25, 25, 25, 64), (None, 25, 25, 25, 64)]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 38, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file0p10s9fe.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)

    TypeError: tf__pcrnet_total_loss() missing 2 required positional arguments: 'rotation_predictions' and 'translation_predictions'

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 1200, in autograph_handler
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 7, in quaternion_error  *
        y_true_q = [Quaternion(q) for q in y_true]

    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/leaky_re_lu_2/LeakyRelu' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/activation/leaky_relu.py", line 72, in call
      return backend.relu(inputs, alpha=self.alpha)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/backend.py", line 5379, in relu
      return tf.nn.leaky_relu(x, alpha=alpha)
Node: 'model/leaky_re_lu_2/LeakyRelu'
OOM when allocating tensor with shape[16,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/leaky_re_lu_2/LeakyRelu}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_8272]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 512 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

2 root error(s) found.
  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Sata500g/my_dataset/results/data/train/params_3142.txt'
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 30, in __getitem__
    with open(self.txt_files[index]) as f:

FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Sata500g/my_dataset/results/data/train/params_3142.txt'


	 [[{{node PyFunc}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional]]
	 [[OptionalHasValue/_6]]
  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Sata500g/my_dataset/results/data/train/params_3142.txt'
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 30, in __getitem__
    with open(self.txt_files[index]) as f:

FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Sata500g/my_dataset/results/data/train/params_3142.txt'


	 [[{{node PyFunc}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_1259601]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 16 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/leaky_re_lu_2/LeakyRelu' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/activation/leaky_relu.py", line 72, in call
      return backend.relu(inputs, alpha=self.alpha)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/backend.py", line 5379, in relu
      return tf.nn.leaky_relu(x, alpha=alpha)
Node: 'model/leaky_re_lu_2/LeakyRelu'
OOM when allocating tensor with shape[16,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/leaky_re_lu_2/LeakyRelu}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_8730]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filezg9ks_08.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filej1psmeeg.py", line 10, in tf__quaternion_error
    true_rotmat = ag__.converted_call(ag__.ld(quaternion_to_rotation_matrix), (ag__.converted_call(ag__.ld(normalize_quaternion), (ag__.ld(true_quaternion),), None, fscope),), None, fscope)
  File "/tmp/__autograph_generated_file1w_e8ai0.py", line 13, in tf__quaternion_to_rotation_matrix
    q_mat = (2 * ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(q_mat), ag__.ld(q_conj)), None, fscope))
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 29, in quaternion_error  *
        true_rotmat = quaternion_to_rotation_matrix(normalize_quaternion(true_quaternion))
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in quaternion_to_rotation_matrix  *
        q_mat = 2 * tf.matmul(q_mat, q_conj)

    ValueError: Dimensions must be equal, but are 5 and 1 for '{{node quaternion_error/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](quaternion_error/concat_4, quaternion_error/mul)' with input shapes: [?,4,5], [?,1,4].

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_files2zo6hnr.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_fileirbut56m.py", line 12, in tf__quaternion_error
    rotmat_diff = ag__.converted_call(ag__.ld(tf).linalg.logm, (ag__.converted_call(ag__.ld(tf).matmul, (ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(true_rotmat),), dict(perm=[0, 2, 1]), fscope), ag__.ld(pred_rotmat)), None, fscope),), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 48, in quaternion_error  *
        rotmat_diff = tf.linalg.logm(tf.matmul(tf.transpose(true_rotmat, perm=[0, 2, 1]), pred_rotmat))

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filetdacfhue.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file2vmyqm7w.py", line 16, in tf__quaternion_error
    rotmat_log = ag__.converted_call(ag__.ld(tf).linalg.logm, (ag__.ld(rotmat_diff),), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 45, in quaternion_error  *
        rotmat_log = tf.linalg.logm(rotmat_diff)

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filekzak3ah9.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filetnrccybe.py", line 16, in tf__quaternion_error
    rotmat_log = ag__.converted_call(ag__.ld(tf).linalg.logm, (ag__.ld(rotmat_diff),), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 45, in quaternion_error  *
        rotmat_log = tf.linalg.logm(rotmat_diff)

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file0df52h3y.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file9mhml5v8.py", line 10, in tf__quaternion_error
    true_rotmat = ag__.converted_call(ag__.ld(quaternion_to_rotation_matrix), (ag__.converted_call(ag__.ld(normalize_quaternion), (ag__.ld(true_quaternion),), None, fscope),), None, fscope)
  File "/tmp/__autograph_generated_fileexngq9ag.py", line 13, in tf__quaternion_to_rotation_matrix
    q_mat = (2 * ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(q_mat), ag__.ld(q_conj)), None, fscope))
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 29, in quaternion_error  *
        true_rotmat = quaternion_to_rotation_matrix(normalize_quaternion(true_quaternion))
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in quaternion_to_rotation_matrix  *
        q_mat = 2 * tf.matmul(q_mat, q_conj)

    ValueError: Dimensions must be equal, but are 5 and 1 for '{{node quaternion_error/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](quaternion_error/concat_4, quaternion_error/mul)' with input shapes: [?,4,5], [?,1,4].

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filegstwxckd.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filejfga1_k6.py", line 12, in tf__quaternion_error
    rotmat_diff = ag__.converted_call(ag__.ld(tf).linalg.logm, (ag__.converted_call(ag__.ld(tf).matmul, (ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(true_rotmat),), dict(perm=[0, 2, 1]), fscope), ag__.ld(pred_rotmat)), None, fscope),), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 42, in quaternion_error  *
        rotmat_diff = tf.linalg.logm(tf.matmul(tf.transpose(true_rotmat, perm=[0, 2, 1]), pred_rotmat))

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'quaternion_error/SelectV2' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 31, in quaternion_error
      true_rotmat = quaternion_to_rotation_matrix(normalize_quaternion(true_quaternion))
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 27, in normalize_quaternion
      return tf.where(tf.less(quaternion[:, 0], 0.), -quaternion, quaternion)
Node: 'quaternion_error/SelectV2'
required broadcastable shapes
	 [[{{node quaternion_error/SelectV2}}]] [Op:__inference_train_function_9512]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'quaternion_error/mul' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 33, in quaternion_error
      true_rotmat = quaternion_to_rotation_matrix(normalize_quaternion(true_quaternion))
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 29, in normalize_quaternion
      return quaternion * flip_sign_mask + (1. - flip_sign_mask) * quaternion
Node: 'quaternion_error/mul'
required broadcastable shapes
	 [[{{node quaternion_error/mul}}]] [Op:__inference_train_function_9562]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 116, in train_pcrnet
    weight_decay=settings.weight_decay,  # 从settings中获取weight_decay参数
AttributeError: 'Arg' object has no attribute 'weight_decay'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 108, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 62, in train_pcrnet_continue
    optimizer = Adam(learning_rate=lr, decay=weight_decay)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/optimizers/adam.py", line 104, in __init__
    super().__init__(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/optimizers/optimizer.py", line 1087, in __init__
    super().__init__(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/optimizers/optimizer.py", line 105, in __init__
    self._process_kwargs(kwargs)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/optimizers/optimizer.py", line 134, in _process_kwargs
    raise ValueError(
ValueError: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 46, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 100, in get_model
    source_features = multi_scale_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 34, in multi_scale_feature_extractor
    net_2 = Conv3D(64, (2, 2, 2), padding='same', strides=(1, 1, 1), kernel_initializer=initializer)(net)
NameError: name 'initializer' is not defined
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/batch_normalization_31/FusedBatchNormV3' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 922, in call
      outputs = self._fused_batch_norm(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 688, in _fused_batch_norm
      output, mean, variance = control_flow_util.smart_cond(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/control_flow_util.py", line 108, in smart_cond
      return tf.__internal__.smart_cond.smart_cond(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 662, in _fused_batch_norm_training
      return tf.compat.v1.nn.fused_batch_norm(
Node: 'model/batch_normalization_31/FusedBatchNormV3'
OOM when allocating tensor with shape[8,64,50,2500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/batch_normalization_31/FusedBatchNormV3}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_33498]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/conv3d_24/Conv3D' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'model/conv3d_24/Conv3D'
OOM when allocating tensor with shape[4,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/conv3d_24/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_33498]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/conv3d_18/Conv3D' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'model/conv3d_18/Conv3D'
OOM when allocating tensor with shape[4,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/conv3d_18/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_25242]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/batch_normalization_12/FusedBatchNormV3' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 53, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 922, in call
      outputs = self._fused_batch_norm(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 688, in _fused_batch_norm
      output, mean, variance = control_flow_util.smart_cond(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/control_flow_util.py", line 108, in smart_cond
      return tf.__internal__.smart_cond.smart_cond(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py", line 662, in _fused_batch_norm_training
      return tf.compat.v1.nn.fused_batch_norm(
Node: 'model/batch_normalization_12/FusedBatchNormV3'
OOM when allocating tensor with shape[4,128,23,529] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/batch_normalization_12/FusedBatchNormV3}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_16986]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 2 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 77, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 60, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/conv3d_5/Conv3D' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 77, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 60, in train_pcrnet_continue
      history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 290, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 262, in convolution_op
      return tf.nn.convolution(
Node: 'model/conv3d_5/Conv3D'
OOM when allocating tensor with shape[8,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/conv3d_5/Conv3D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_13882]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 102, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 81, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 50, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(y_true, y_pred)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 20, in evaluate_metrics
    quaternion_diff = quaternion_error(y_true['rotation'], y_pred['rotation'])
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 107, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 86, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 50, in on_epoch_end
    y_true_rotation = y_true['rotation']
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 106, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 85, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 50, in on_epoch_end
    y_true_rotation = y_true['rotation']
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 103, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 82, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 41, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(y_true,
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 20, in evaluate_metrics
    quaternion_diff = quaternion_error(y_true['rotation'], y_pred['rotation'])
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 103, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 82, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 41, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(y_true,
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 20, in evaluate_metrics
    quaternion_diff = y_true['rotation'] - y_pred['rotation']
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 105, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 84, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 52, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 23, in evaluate_metrics
    quaternion_diff = quaternion_error(y_true_dict['rotation'], y_pred_dict['rotation'])
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 107, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 86, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 26, in evaluate_metrics
    quaternion_diff = quaternion_error(y_true_dict['rotation'], y_pred_dict['rotation'])
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 108, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 87, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 24, in evaluate_metrics
    y_true_dict = {key: value.numpy() for key, value in y_true[1].items()}
KeyError: 1
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 109, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 88, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 56, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 25, in evaluate_metrics
    y_true_dict = {key: value.numpy() for key, value in y_true[1].items()}
KeyError: 1
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 109, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 88, in train_pcrnet_continue
    history = model.fit(train_dist_dataset, validation_data=test_dist_dataset, epochs=epochs,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 56, in on_epoch_end
    avg_diff_quaternion, std_dev_quaternion, avg_diff_translation, std_dev_translation = evaluate_metrics(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 23, in evaluate_metrics
    print('y_true[rotation]', y_true['rotation'])
KeyError: 'rotation'
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    print('rotation', test_data['rotation'])
TypeError: '_PrefetchDataset' object is not subscriptable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    print('rotation', test_data[1]['rotation'])
TypeError: '_PrefetchDataset' object is not subscriptable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    print('rotation', test_data.take(1)['rotation'])
TypeError: '_TakeDataset' object is not subscriptable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 135, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    print('rotation', test_data.take(1)[1]['rotation'])
TypeError: '_TakeDataset' object is not subscriptable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 64 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 5 --subtomo_size 50 --gpuID 0 --batch_size 4 --select_subtomo_number 1024 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    average_ini(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/average.py", line 108, in average_ini
    mrc_path = list(settings.mrc_list)[7]
IndexError: list index out of range
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    average_ini(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/average.py", line 108, in average_ini
    mrc_path = list(settings.mrc_list)[7]
IndexError: list index out of range
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1697, in fit
    raise ValueError(
ValueError: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1697, in fit
    raise ValueError(
ValueError: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --select_subtomo_number 1 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1697, in fit
    raise ValueError(
ValueError: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1697, in fit
    raise ValueError(
ValueError: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/leaky_re_lu_18/LeakyRelu' defined at (most recent call last):
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 155, in <module>
      fire.Fire(SELFALIGN)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
      component_trace = _Fire(component, args, parsed_flag_args, context, name)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
      component, remaining_args = _CallAndUpdateTrace(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
      component = fn(*varargs, **kwargs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py", line 98, in refine
      run(d_args)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
      history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
      history = train_pcrnet_continue(
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
      history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function
      return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/activation/leaky_relu.py", line 72, in call
      return backend.relu(inputs, alpha=self.alpha)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/backend.py", line 5379, in relu
      return tf.nn.leaky_relu(x, alpha=alpha)
Node: 'model/leaky_re_lu_18/LeakyRelu'
OOM when allocating tensor with shape[8,64,50,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/leaky_re_lu_18/LeakyRelu}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_13664]
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 30 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 45, in run
    from SelfAlign.models.pcrnet.predict import predict
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 7, in <module>
    from SelfAlign.preprocessing.img_processing import save_params_to_txt, save_params_to_txt_worker, normalize_z_score
ImportError: cannot import name 'save_params_to_txt_worker' from 'SelfAlign.preprocessing.img_processing' (/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py)
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 65, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 25, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 368, in class_and_config_for_serialized_keras_object
    raise ValueError(
ValueError: Unknown layer: 'SpectralPooling'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/results --rota /media/hao/Sata500g/my_dataset/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 28, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 520, in deserialize_keras_object
    deserialized_obj = cls(**cls_config)
TypeError: 'module' object is not callable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 67, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 27, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 520, in deserialize_keras_object
    deserialized_obj = cls(**cls_config)
TypeError: 'module' object is not callable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 56, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 50, in get_model
    source_features = shared_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 14, in shared_feature_extractor
    shared_conv1 = DCTPooling3D((26, 26, 26), (22, 22, 22))(shared_conv1)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filem0388h9i.py", line 26, in tf__call
    x_dct = ag__.converted_call(ag__.ld(self)._dct3D, (ag__.ld(inputs),), None, fscope)
  File "/tmp/__autograph_generated_filejt1m5t7h.py", line 12, in tf___dct3D
    retval_ = ag__.converted_call(ag__.ld(tf).signal.dct3d, (ag__.ld(x),), dict(norm='ortho'), fscope)
AttributeError: Exception encountered when calling layer "dct_pooling3d" (type DCTPooling3D).

in user code:

    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 26, in call  *
        x_dct = self._dct3D(inputs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 44, in _dct3D  *
        return tf.signal.dct3d(x, norm='ortho')

    AttributeError: module 'tensorflow._api.v2.signal' has no attribute 'dct3d'


Call arguments received by layer "dct_pooling3d" (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(None, 48, 48, 48, 32), dtype=float32)
  • mask=None
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 56, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 50, in get_model
    source_features = shared_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 14, in shared_feature_extractor
    shared_conv1 = DCTPooling3D((26, 26, 26), (22, 22, 22))(shared_conv1)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file4v5pnpvt.py", line 26, in tf__call
    x_dct = ag__.converted_call(ag__.ld(self)._dct3D, (ag__.ld(inputs),), None, fscope)
  File "/tmp/__autograph_generated_fileto4kylvg.py", line 12, in tf___dct3D
    retval_ = ag__.converted_call(ag__.ld(custom_dct3d), (ag__.ld(x),), dict(norm='ortho'), fscope)
  File "/tmp/__autograph_generated_filepcrb5hkp.py", line 12, in tf__custom_dct3d
    x_dct2d = ag__.converted_call(ag__.ld(tf).signal.dct, (ag__.ld(x_reshaped),), dict(axis=[(- 2), (- 1)], norm=ag__.ld(norm)), fscope)
NotImplementedError: Exception encountered when calling layer "dct_pooling3d" (type DCTPooling3D).

in user code:

    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 43, in call  *
        x_dct = self._dct3D(inputs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 61, in _dct3D  *
        return custom_dct3d(x, norm='ortho')
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 12, in custom_dct3d  *
        x_dct2d = tf.signal.dct(x_reshaped, axis=[-2, -1], norm=norm)

    NotImplementedError: axis must be -1. Got: [-2, -1]


Call arguments received by layer "dct_pooling3d" (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(None, 48, 48, 48, 32), dtype=float32)
  • mask=None
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 56, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 50, in get_model
    source_features = shared_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 14, in shared_feature_extractor
    shared_conv1 = DCTPooling3D((26, 26, 26), (22, 22, 22))(shared_conv1)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file3jrlymxu.py", line 26, in tf__call
    x_dct = ag__.converted_call(ag__.ld(self)._dct3D, (ag__.ld(inputs),), None, fscope)
  File "/tmp/__autograph_generated_filexzij_qzo.py", line 11, in tf___dct3D
    x_dct_length = ag__.converted_call(ag__.ld(tf).signal.dct, (ag__.ld(x_transposed),), dict(axis=2, norm='ortho'), fscope)
NotImplementedError: Exception encountered when calling layer "dct_pooling3d" (type DCTPooling3D).

in user code:

    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 26, in call  *
        x_dct = self._dct3D(inputs)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 48, in _dct3D  *
        x_dct_length = tf.signal.dct(x_transposed, axis=2, norm='ortho')

    NotImplementedError: axis must be -1. Got: 2


Call arguments received by layer "dct_pooling3d" (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(None, 48, 48, 48, 32), dtype=float32)
  • mask=None
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 63, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 23, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 368, in class_and_config_for_serialized_keras_object
    raise ValueError(
ValueError: Unknown layer: 'DCTPooling3D'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 66, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 26, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 520, in deserialize_keras_object
    deserialized_obj = cls(**cls_config)
TypeError: 'module' object is not callable
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 66, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filenrao47is.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_fileg2in35p7.py", line 10, in tf__quaternion_frobenius_loss
    y_true_matrix = ag__.converted_call(ag__.ld(quaternion_to_rotation_matrix), (ag__.ld(y_true),), None, fscope)
  File "/tmp/__autograph_generated_fileird6mjg5.py", line 13, in tf__quaternion_to_rotation_matrix
    (qw, qx, qy, qz) = ag__.converted_call(ag__.ld(tf).unstack, (ag__.ld(w),), dict(num=4, axis=(- 1)), fscope)
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 37, in quaternion_frobenius_loss  *
        y_true_matrix = quaternion_to_rotation_matrix(y_true)
    File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 26, in quaternion_to_rotation_matrix  *
        qw, qx, qy, qz = tf.unstack(w, num=4, axis=-1)

    ValueError: Dimension must be 4 but is 1 for '{{node quaternion_frobenius_loss/unstack}} = Unpack[T=DT_FLOAT, axis=-1, num=4](quaternion_frobenius_loss/split)' with input shapes: [?,1].

/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 4 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 45, in run
    from SelfAlign.models.pcrnet.predict import predict
  File "/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 6, in <module>
    from SelfAlign.models.pcrnet.tf_util_loss import quaternion_error, translation_loss
ImportError: cannot import name 'quaternion_error' from 'SelfAlign.models.pcrnet.tf_util_loss' (/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py)
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/BaiduSyncdisk/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 59, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 58, in get_model
    source_features = shared_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 16, in shared_feature_extractor
    tf.print("shared_conv1 Shape:", tf.shape(shared_conv1))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/core/tf_op_layer.py", line 119, in handle
    return TFOpLambda(op)(*args, **kwargs)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
TypeError: Could not build a TypeSpec for name: "tf.print/PrintV2"
op: "PrintV2"
input: "tf.print/StringFormat"
attr {
  key: "output_stream"
  value {
    s: "stderr"
  }
}
attr {
  key: "end"
  value {
    s: "\n"
  }
}
 of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 59, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 64, in get_model
    print("Flatten Shape:", tf.shape(Flatten))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py", line 103, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Attempt to convert a value (<class 'keras.layers.reshaping.flatten.Flatten'>) with an unsupported type (<class 'type'>) to a Tensor.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 40 --subtomo_size 50 --gpuID 0 --batch_size 8 --result_dir /media/hao/Sata500g/my_dataset/class_binned4/results --rota /media/hao/Sata500g/my_dataset/class_binned4/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 66, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

2 root error(s) found.
  (0) INVALID_ARGUMENT:  ValueError: operands could not be broadcast together with shapes (40,40,40) (50,50,50) 
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 43, in __getitem__
    [get_mrc_data(p)[:, :, :, np.newaxis] for p in source_mrc_paths], dtype=np.float32)

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 43, in <listcomp>
    [get_mrc_data(p)[:, :, :, np.newaxis] for p in source_mrc_paths], dtype=np.float32)

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 17, in get_mrc_data
    return cdata * mask_binned4

ValueError: operands could not be broadcast together with shapes (40,40,40) (50,50,50) 


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_2]]
  (1) INVALID_ARGUMENT:  ValueError: operands could not be broadcast together with shapes (40,40,40) (50,50,50) 
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 43, in __getitem__
    [get_mrc_data(p)[:, :, :, np.newaxis] for p in source_mrc_paths], dtype=np.float32)

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 43, in <listcomp>
    [get_mrc_data(p)[:, :, :, np.newaxis] for p in source_mrc_paths], dtype=np.float32)

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 17, in get_mrc_data
    return cdata * mask_binned4

ValueError: operands could not be broadcast together with shapes (40,40,40) (50,50,50) 


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_32836]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 50 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 76, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 106, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 76, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 106, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 76, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 106, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(get_cubes, inp, rota_folder)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 485, in _map_async
    result = MapResult(self, chunksize, len(iterable), callback,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 797, in __init__
    if chunksize <= 0:
TypeError: '<=' not supported between instances of 'str' and 'int'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 105, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
TypeError: get_cubes() missing 1 required positional argument: 'start'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 103, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
TypeError: get_cubes() missing 1 required positional argument: 'start'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 75, in get_cubes
    for temple_mrc, start in batch_temple_mrcs, batch_indices:
ValueError: too many values to unpack (expected 2)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 104, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: too many values to unpack (expected 2)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 119, in get_cubes_list
    ind = np.random.choice(all_path_x, num_test, replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 120, in get_cubes_list
    ind = np.random.choice(all_path_x, num_test, replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 66, in get_cubes
    temp_data_list.append({
NameError: name 'temp_data_list' is not defined
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 96, in run
    get_cubes_list(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/prepare.py", line 107, in get_cubes_list
    p.map(func, inp)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/hao/anaconda3/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
NameError: name 'temp_data_list' is not defined
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 79, in prepare_custom_dataseq
    train_txt = read_non_empty_lines(train_txt_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 92, in read_non_empty_lines
    with open(file_path, 'r', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results/data/train_/1.txt'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 79, in prepare_custom_dataseq
    train_txt = read_non_empty_lines(train_txt_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 92, in read_non_empty_lines
    with open(file_path, 'r', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results/datatrain_1.txt'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 79, in prepare_custom_dataseq
    train_txt = read_non_empty_lines(train_txt_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 92, in read_non_empty_lines
    with open(file_path, 'r', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results/data/train_1.txt'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 37, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

2 root error(s) found.
  (0) INVALID_ARGUMENT:  ValueError: could not convert string to float: 'edia'
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 32, in __getitem__
    quaternion = np.array(line[2:6], dtype=np.float32)

ValueError: could not convert string to float: 'edia'


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_4]]
  (1) INVALID_ARGUMENT:  ValueError: could not convert string to float: 'edia'
Traceback (most recent call last):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py", line 267, in __call__
    ret = func(*args)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in __iter__
    for item in (self[i] for i in range(len(self))):

  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/data_utils.py", line 566, in <genexpr>
    for item in (self[i] for i in range(len(self))):

  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 32, in __getitem__
    quaternion = np.array(line[2:6], dtype=np.float32)

ValueError: could not convert string to float: 'edia'


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_32836]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 78, in prepare_custom_dataseq
    train_txt = read_non_empty_lines(train_txt_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 98, in read_non_empty_lines
    non_empty_lines.append(source_mrc_path, template_mrc_path,
TypeError: append() takes exactly one argument (4 given)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 68, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 35, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 78, in prepare_custom_dataseq
    train_txt = read_non_empty_lines(train_txt_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 98, in read_non_empty_lines
    non_empty_lines.append({source_mrc_path, template_mrc_path,
TypeError: unhashable type: 'numpy.ndarray'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 100 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 73, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 33, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 86, in prepare_custom_dataseq
    if repeat:
NameError: name 'repeat' is not defined
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 45, in run
    from SelfAlign.models.pcrnet.predict import predict
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 6, in <module>
    from SelfAlign.models.pcrnet.tf_util_loss import translation_loss, quaternion_frobenius_loss
ImportError: cannot import name 'quaternion_frobenius_loss' from 'SelfAlign.models.pcrnet.tf_util_loss' (/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 63, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 103, in get_model
    rotation = Dense(4, weights=weights)(dense2)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1827, in set_weights
    raise ValueError(
ValueError: Layer dense_2 weight shape (2000, 4) is not compatible with provided weight shape (2000, 6).
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 70, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 24, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 368, in class_and_config_for_serialized_keras_object
    raise ValueError(
ValueError: Unknown layer: 'FeatureL2Norm'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 71, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 25, in train_pcrnet_continue
    model = load_model(model_file, custom_objects=custom_objects)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 368, in class_and_config_for_serialized_keras_object
    raise ValueError(
ValueError: Unknown layer: 'FeatureCorrelation'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 72, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileqvlim81u.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filedek6gmcl.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filef41_7l_k.py", line 13, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_filedek6gmcl.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filef41_7l_k.py", line 13, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 30, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0*h0*w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • tensors=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 72, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filegzoctb7g.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file3fafz6vx.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filecwktnt6g.py", line 13, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3fafz6vx.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filecwktnt6g.py", line 13, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 30, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0*h0*w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • tensors=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 72, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 40, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filen31toa4n.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filew3ojxvff.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_fileos6wn84f.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_filew3ojxvff.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_fileos6wn84f.py", line 14, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 30, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0*h0*w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • tensors=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 72, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileaihi1m_i.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filennwwv_j9.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filehyh8tojw.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_filennwwv_j9.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filehyh8tojw.py", line 14, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 30, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0*h0*w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • tensors=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 73, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 33, in train_pcrnet_continue
    print("train.shape, test.shape=", train_data.shape, test_data.shape)
AttributeError: '_PrefetchDataset' object has no attribute 'shape'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 81, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    source_volume_shape = example['source_volume_input'].shape
TypeError: tuple indices must be integers or slices, not str
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 81, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 34, in train_pcrnet_continue
    source_volume_shape = example[1]['source_volume_input'].shape
KeyError: 'source_volume_input'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 74, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 36, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileth71t8y0.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filet31qkc7q.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filevb0jgte7.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_filet31qkc7q.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filevb0jgte7.py", line 14, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 30, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0*h0*w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • tensors=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 61, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 44, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filelj32p4h5.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_fileqysw51m7.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(_feature_correlation), (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_fileappqci4l.py", line 14, in tf___feature_correlation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A),), dict(shape=((- 1), ((ag__.ld(length_0) * ag__.ld(height_0)) * ag__.ld(width_0)), ag__.ld(c))), fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_fileqysw51m7.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(_feature_correlation), (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_fileappqci4l.py", line 14, in tf___feature_correlation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A),), dict(shape=((- 1), ((ag__.ld(length_0) * ag__.ld(height_0)) * ag__.ld(width_0)), ag__.ld(c))), fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 46, in call  *
            output = _feature_correlation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 11, in _feature_correlation  *
            f_A = tf.reshape(f_A, shape=(-1, length_0 * height_0 * width_0, c))
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • inputs=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 61, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 44, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filea0n2g6cv.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file7dc0wo4d.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(_feature_correlation), (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filez0oj4gi4.py", line 14, in tf___feature_correlation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A),), dict(shape=((- 1), ((ag__.ld(length_0) * ag__.ld(height_0)) * ag__.ld(width_0)), ag__.ld(c))), fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file7dc0wo4d.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(_feature_correlation), (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filez0oj4gi4.py", line 14, in tf___feature_correlation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A),), dict(shape=((- 1), ((ag__.ld(length_0) * ag__.ld(height_0)) * ag__.ld(width_0)), ag__.ld(c))), fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 46, in call  *
            output = _feature_correlation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 11, in _feature_correlation  *
            f_A = tf.reshape(f_A, shape=(-1, length_0 * height_0 * width_0, c))
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • inputs=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 53, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 692, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 61, in call  *
        output = _feature_correlation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 24, in _feature_correlation  *
        assert c == c_, "Number of channels must be equal"

    OperatorNotAllowedInGraphError: Using a symbolic `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 8, 8, 8, 512), dtype=float32)', 'tf.Tensor(shape=(None, 8, 8, 8, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 59, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 48, in get_model
    v_s = shared_feature_extractor(source_volume_input)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 16, in shared_feature_extractor
    shared_conv1 = DCTPooling3D((26, 26, 26), (22, 22, 22))(shared_conv1)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file_x9qm540.py", line 26, in tf__call
    x_dct = ag__.converted_call(ag__.ld(self)._dct3D, (ag__.ld(inputs),), None, fscope)
  File "/tmp/__autograph_generated_fileczh5sija.py", line 10, in tf___dct3D
    x_perm = ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(x),), dict(perm=[0, 4, 1, 2, 3]), fscope)
ValueError: Exception encountered when calling layer "dct_pooling3d" (type DCTPooling3D).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 28, in call  *
        x_dct = self._dct3D(inputs)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 38, in _dct3D  *
        x_perm = tf.transpose(x, perm=[0, 4, 1, 2, 3])

    ValueError: Dimension must be 6 but is 5 for '{{node dct_pooling3d/transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](Placeholder, dct_pooling3d/transpose/perm)' with input shapes: [?,?,38,38,38,32], [5].


Call arguments received by layer "dct_pooling3d" (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(None, None, 38, 38, 38, 32), dtype=float32)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 59, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 54, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 54, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 54, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 54, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 53, in get_model
    c_st = FeatureCorrelation()(v_s, v_t)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 439, in converted_call
    result = converted_f(*effective_args, **kwargs)
TypeError: in user code:


    TypeError: tf__call() takes 2 positional arguments but 3 were given

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 61, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 44, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file4lhet62t.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_filevzpk04y9.py", line 10, in tf__call
    (quats_true, trans_true) = ag__.converted_call(ag__.ld(tf).split, (ag__.ld(y_true), [4, 3]), dict(axis=(- 1)), fscope)
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 27, in call  *
        quats_true, trans_true = tf.split(y_true, [4, 3], axis=-1)

    ValueError: can't split axis of size 4 into pieces of size [4,3] for '{{node joint_quaternion_translation_loss/split}} = SplitV[T=DT_FLOAT, Tlen=DT_INT32, num_split=2](cond/Identity_2, joint_quaternion_translation_loss/Const, joint_quaternion_translation_loss/split/split_dim)' with input shapes: [?,4], [2], [] and with computed input tensors: input[1] = <4 3>, input[2] = <-1>.

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 12 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

2 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[6144,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation_1/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_2/ReadVariableOp/_468]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[6144,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation_1/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35152]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

2 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[4096,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp/_490]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[4096,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35152]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 6 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

2 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[3072,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation_1/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp/_490]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[3072,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation_1/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35152]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

2 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2048,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan/ReadVariableOp_1/_500]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[2048,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/feature_correlation/ArithmeticOptimizer/FoldTransposeIntoMatMul_MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35152]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 54, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'model/layer_normalization_12/add' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/layer_normalization.py", line 348, in call
      outputs = outputs + tf.cast(offset, outputs.dtype)
Node: 'model/layer_normalization_12/add'
Detected at node 'model/layer_normalization_12/add' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
      y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 558, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/base_layer.py", line 1145, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/normalization/layer_normalization.py", line 348, in call
      outputs = outputs + tf.cast(offset, outputs.dtype)
Node: 'model/layer_normalization_12/add'
2 root error(s) found.
  (0) RESOURCE_EXHAUSTED:  failed to allocate memory
	 [[{{node model/layer_normalization_12/add}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp/_490]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) RESOURCE_EXHAUSTED:  failed to allocate memory
	 [[{{node model/layer_normalization_12/add}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35216]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1000 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 64, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 47, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in translation_loss
      return tf.reduce_mean(tf.reduce_sum(tf.square(y_true - y_pred), axis=-1), axis=-1)
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in translation_loss
      return tf.reduce_mean(tf.reduce_sum(tf.square(y_true - y_pred), axis=-1), axis=-1)
Node: 'translation_loss/sub'
2 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan_1/ReadVariableOp/_490]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35216]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 1 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 1 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 1 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 62, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 45, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in translation_loss
      return tf.reduce_mean(tf.reduce_sum(tf.square(y_true - y_pred), axis=-1), axis=-1)
Node: 'translation_loss/sub'
Detected at node 'translation_loss/sub' defined at (most recent call last):
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 890, in _bootstrap
      self._bootstrap_inner()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/threading.py", line 932, in _bootstrap_inner
      self.run()
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step
      outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
      return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 142, in __call__
      losses = call_fn(y_true, y_pred)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 268, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 17, in translation_loss
      return tf.reduce_mean(tf.reduce_sum(tf.square(y_true - y_pred), axis=-1), axis=-1)
Node: 'translation_loss/sub'
2 root error(s) found.
  (0) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
	 [[div_no_nan/ReadVariableOp/_494]]
  (1) INVALID_ARGUMENT:  required broadcastable shapes
	 [[{{node translation_loss/sub}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_35202]
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filese95y5he.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._feature_correlation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
AttributeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 26, in call  *
        output = self._feature_correlation(f_A=f_A, f_B=f_B)

    AttributeError: 'FeatureCorrelation' object has no attribute '_feature_correlation'


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file6ynz_yex.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_file3pf0d898.py", line 13, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [ag__.ld(b), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 26, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 38, in _featurecorrelation  *
        f_A = tf.reshape(f_A, [b, l0 * h0 * w0, c])

    TypeError: Failed to convert elements of [None, 216, 512] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file1wzb8h6x.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_fileslbcxo70.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [ag__.ld(b), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 40, in _featurecorrelation  *
        f_A = tf.reshape(f_A, [b, l0 * h0 * w0, c])

    TypeError: Failed to convert elements of [None, 216, 512] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filely7dfp1x.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_fileox2yxvar.py", line 16, in tf___featurecorrelation
    f_B = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_B), [ag__.ld(b), ((ag__.ld(l) * ag__.ld(h)) * ag__.ld(w)), ag__.ld(c)]), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
        f_B = tf.reshape(f_B, [b, l * h * w, c])

    TypeError: Failed to convert elements of [None, 216, 512] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileq45na3vl.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filecgvsm9oi.py", line 20, in tf___featurecorrelation
    correlation_tensor = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_mul), [ag__.ld(b), ag__.ld(l), ag__.ld(h), ag__.ld(w), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0))]), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 48, in _featurecorrelation  *
        correlation_tensor = tf.reshape(f_mul, [b, l, h, w, l0 * h0 * w0])

    TypeError: Failed to convert elements of [None, 6, 6, 6, 216] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 62, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 45, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileykso89_2.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file3njwi6mm.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filekn5g9a1b.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3njwi6mm.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_filekn5g9a1b.py", line 14, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 40, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0 * h0 * w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • inputs=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 102, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 62, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 45, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filet34apfqj.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file0m804zr0.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_fileybkuf_cj.py", line 14, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)
TypeError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file0m804zr0.py", line 11, in tf__call
        output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
    File "/tmp/__autograph_generated_fileybkuf_cj.py", line 14, in tf___featurecorrelation
        f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0)), ag__.ld(c)]), None, fscope)

    TypeError: Exception encountered when calling layer 'feature_correlation_1' (type FeatureCorrelation).
    
    in user code:
    
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
            output = self._featurecorrelation(f_A=f_A, f_B=f_B)
        File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 40, in _featurecorrelation  *
            f_A = tf.reshape(f_A, [-1, l0 * h0 * w0, c])
    
        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
    
    
    Call arguments received by layer 'feature_correlation_1' (type FeatureCorrelation):
      • inputs=['tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)', 'tf.Tensor(shape=(None, None, None, None, 512), dtype=float32)']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 57, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 59, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 60, in get_model
    c_st = Conv3D(1024, (3, 3, 3))(c_st)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 69, in get_model
    c_ts = Conv3D(1024, (3, 3, 3))(c_ts)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py", line 416, in _get_input_channel
    raise ValueError(
ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 68, in get_model
    c_st = tf.ensure_shape(c_st, [None, None, None, None, 1])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/core/tf_op_layer.py", line 119, in handle
    return TFOpLambda(op)(*args, **kwargs)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
ValueError: Exception encountered when calling layer "tf.ensure_shape_1" (type TFOpLambda).

Shape must be rank 5 but is rank 2 for '{{node tf.ensure_shape_1/EnsureShape}} = EnsureShape[T=DT_FLOAT, shape=[?,?,?,?,1]](Placeholder)' with input shapes: [?,?].

Call arguments received by layer "tf.ensure_shape_1" (type TFOpLambda):
  • x=tf.Tensor(shape=(None, None), dtype=float32)
  • shape=['None', 'None', 'None', 'None', '1']
  • name=None
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 83, in get_model
    dense1 = Dense(2000)(c)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/core/dense.py", line 148, in build
    raise ValueError(
ValueError: The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file3zgml1eo.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_file7ce03cp0.py", line 18, in tf___featurecorrelation
    output_shape = ag__.converted_call(ag__.ld(tf).TensorShape, ([ag__.ld(b), ag__.ld(l), ag__.ld(h), ag__.ld(w), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0))],), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 48, in _featurecorrelation  *
        output_shape = tf.TensorShape([b, l, h, w, l0 * h0 * w0])

    TypeError: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'feature_correlation/unstack_1:0' shape=() dtype=int32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filetr4qlfpk.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filegqnejaek.py", line 17, in tf___featurecorrelation
    output_shape = ag__.converted_call(ag__.ld(tf).TensorShape, ([ag__.ld(b), ag__.ld(l), ag__.ld(h), ag__.ld(w), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0))],), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 47, in _featurecorrelation  *
        output_shape = tf.TensorShape([b, l, h, w, l0 * h0 * w0])

    TypeError: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'feature_correlation/unstack_1:0' shape=() dtype=int32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filej0gywtlf.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_file1l81qero.py", line 18, in tf___featurecorrelation
    output_shape = ag__.converted_call(ag__.ld(tf).TensorShape, ([ag__.ld(b), ag__.ld(l), ag__.ld(h), ag__.ld(w), ((ag__.ld(l0) * ag__.ld(h0)) * ag__.ld(w0))],), None, fscope)
TypeError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 27, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 48, in _featurecorrelation  *
        output_shape = tf.TensorShape([b, l, h, w, l0 * h0 * w0])

    TypeError: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'feature_correlation/unstack_1:0' shape=() dtype=int32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file1hvbh2m8.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_filesctil_f2.py", line 17, in tf___featurecorrelation
    f_A = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_A), [(- 1), ag__.ld(l0_h0_w0), ag__.ld(c)]), None, fscope)
NameError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 24, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 43, in _featurecorrelation  *
        f_A = tf.reshape(f_A, [-1, l0_h0_w0, c])

    NameError: name 'c' is not defined


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 55, in get_model
    c_st = FeatureCorrelation()([v_s, v_t])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filexho0wvwz.py", line 11, in tf__call
    output = ag__.converted_call(ag__.ld(self)._featurecorrelation, (), dict(f_A=ag__.ld(f_A), f_B=ag__.ld(f_B)), fscope)
  File "/tmp/__autograph_generated_file1qpqp8r2.py", line 22, in tf___featurecorrelation
    correlation_tensor = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(f_mul), [ag__.ld(output_shape)]), None, fscope)
ValueError: Exception encountered when calling layer "feature_correlation" (type FeatureCorrelation).

in user code:

    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 24, in call  *
        output = self._featurecorrelation(f_A=f_A, f_B=f_B)
    File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/FeatureCorrelation.py", line 50, in _featurecorrelation  *
        correlation_tensor = tf.reshape(f_mul, [output_shape])

    ValueError: Shape must be rank 1 but is rank 2 for '{{node feature_correlation/Reshape_2}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](feature_correlation/MatMul, feature_correlation/Reshape_2/shape)' with input shapes: [?,216,216], [1,5].


Call arguments received by layer "feature_correlation" (type FeatureCorrelation):
  • inputs=['tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)', 'tf.Tensor(shape=(None, 6, 6, 6, 512), dtype=float32)']
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 86, in run
    prepare_first_model(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 55, in prepare_first_model
    model = get_model(input_shape)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/PCR_Net.py", line 56, in get_model
    c_st = tf.ensure_shape(c_st, [None, None, None, None, 1])
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/layers/core/tf_op_layer.py", line 119, in handle
    return TFOpLambda(op)(*args, **kwargs)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
ValueError: Exception encountered when calling layer "tf.ensure_shape" (type TFOpLambda).

Dimension 4 in both shapes must be equal, but are 1 and 216. Shapes are [?,?,?,?,1] and [?,6,6,6,216]. for '{{node tf.ensure_shape/EnsureShape}} = EnsureShape[T=DT_FLOAT, shape=[?,?,?,?,1]](Placeholder)' with input shapes: [?,6,6,6,216].

Call arguments received by layer "tf.ensure_shape" (type TFOpLambda):
  • x=tf.Tensor(shape=(None, 6, 6, 6, 216), dtype=float32)
  • shape=['None', 'None', 'None', 'None', '1']
  • name=None
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 2 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 4 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --iterations 50 --subtomo_size 40 --gpuID 0 --batch_size 8 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 128 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 63, in run
    args.mrc_list = np.random.choice(args.all_mrc_list, size=int(args.select_subtomo_number), replace=False)
  File "mtrand.pyx", line 965, in numpy.random.mtrand.RandomState.choice
ValueError: Cannot take a larger sample than population when 'replace=False'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 128 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 128 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    predict(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 26, in predict
    model = load_model('{}/model_iter{:0>2d}.h5'.format(settings.result_dir, settings.iter_count - 1),
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/saving/legacy/serialization.py", line 543, in deserialize_keras_object
    raise ValueError(
ValueError: Unknown loss function: 'quaternion_angle_loss'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    predict(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 32, in predict
    temple_data = get_mrc_data(temple_mrc_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 15, in get_mrc_data
    with mrcfile.open(mrc_path, permissive=True) as cdata:
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/results/tmp_1.mrc'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    predict(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 32, in predict
    temple_data = get_mrc_data(temple_mrc_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 15, in get_mrc_data
    with mrcfile.open(mrc_path, permissive=True) as cdata:
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/results/tmp_1.mrc'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 105, in run
    predict(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 32, in predict
    temple_data = get_mrc_data(temple_mrc_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 15, in get_mrc_data
    with mrcfile.open(mrc_path, permissive=True) as cdata:
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/results/tmp_1.mrc'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 107, in run
    predict(args)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/predict.py", line 32, in predict
    temple_data = get_mrc_data(temple_mrc_path)
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/preprocessing/img_processing.py", line 15, in get_mrc_data
    with mrcfile.open(mrc_path, permissive=True) as cdata:
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/media/hao/Hard_disk_1T/datasets/results/tmp_2.mrc'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 110, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 67, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 57, in on_epoch_end
    rotation_errors, rotation_std, translation_errors, translation_std = compute_errors(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 18, in compute_errors
    rotation_diffs = y_true['rotation'] - y_pred['rotation']
TypeError: '_UnbatchDataset' object is not subscriptable
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 116, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 73, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in on_epoch_end
    val_predictions = model.predict(val_labels)
  File "/tmp/__autograph_generated_file5kv_chzk.py", line 15, in tf__predict_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2169, in predict_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2155, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2143, in run_step  **
        outputs = model.predict_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2111, in predict_step
        return self(x, training=False)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/input_spec.py", line 197, in assert_input_compatibility
        raise ValueError(

    ValueError: Missing data for input "source_volume_input". You passed a data dictionary with keys ['rotation', 'translation']. Expected the following keys: ['source_volume_input', 'template_volume_input']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 73, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 58, in on_epoch_end
    val_predictions = model.predict(val_labels)
  File "/tmp/__autograph_generated_file3cat82ks.py", line 15, in tf__predict_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2169, in predict_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2155, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2143, in run_step  **
        outputs = model.predict_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 2111, in predict_step
        return self(x, training=False)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/input_spec.py", line 197, in assert_input_compatibility
        raise ValueError(

    ValueError: Missing data for input "source_volume_input". You passed a data dictionary with keys ['rotation', 'translation']. Expected the following keys: ['source_volume_input', 'template_volume_input']

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/models/pcrnet/train.py", line 98, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filetwp27thb.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1051, in train_step
        loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1109, in compute_loss
        return self.compiled_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/engine/compile_utils.py", line 265, in __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/losses.py", line 160, in __call__
        return losses_utils.compute_weighted_loss(
    File "/home/hao/anaconda3/envs/align/lib/python3.8/site-packages/keras/utils/losses_utils.py", line 328, in compute_weighted_loss
        losses = tf.convert_to_tensor(losses)

    ValueError: None values not supported.

/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 40 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 32 --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/results --rota /media/hao/Hard_disk_1T/datasets/rota --preprocessing_ncpus 12
Traceback (most recent call last):
  File "/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/refine.py", line 65, in run
    args.mrc_list = np.random.choice(args.all_mrc_list, size=int(args.select_subtomo_number), replace=False)
  File "mtrand.pyx", line 965, in numpy.random.mtrand.RandomState.choice
ValueError: Cannot take a larger sample than population when 'replace=False'
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/media/hao/Sata500g/Beijing/ISBRA-2024/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 0 --batch_size 16 --result_dir /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/results --rota /media/hao/Hard_disk_1T/datasets/my_dataset/class_binned5/rota --preprocessing_ncpus 12
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/class/results_smi --rota /HBV/Caohaofan/class/simulation
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/class/results_smi/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 256 --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 256 --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofanresults_smi --rota /HBV/Caohaofan/simulation
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofanresults_smi --rota /HBV/Caohaofan/simulation
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 256 --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --select_subtomo_number 256 --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22.
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 118, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 118, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 118, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 97, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 107, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 119, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results/data/test/test_1.txt'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 122, in run
    get_cubes_list(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 116, in get_cubes_list
    all_path_x = len(temp_data_list)
UnboundLocalError: local variable 'temp_data_list' referenced before assignment
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 122, in run
    get_cubes_list(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 131, in get_cubes_list
    temp_data_list.clear()
AttributeError: 'ListProxy' object has no attribute 'clear'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 37, in get_cubes
    with mrcfile.open(mrc) as mrcData:
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/simulation_degree30/rotated_51.mrc'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 122, in run
    get_cubes_list(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 106, in get_cubes_list
    p.map(func, inp)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/simulation_degree30/rotated_51.mrc'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 98, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filebn2idl8v.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file7s_7z841.py", line 10, in tf__quaternion_angle_loss
    ag__.converted_call(ag__.ld(save_values_with_labels_to_txt), (ag__.ld(rotation_loss_file), 'y_true', ag__.ld(y_true)), None, fscope)
  File "/tmp/__autograph_generated_file5x9talm6.py", line 23, in tf__save_values_with_labels_to_txt
    ag__.for_stmt(ag__.ld(values), None, loop_body, get_state, set_state, (), {'iterate_names': 'value'})
  File "/tmp/__autograph_generated_file5x9talm6.py", line 20, in loop_body
    ag__.converted_call(ag__.ld(f).write, (f'''{ag__.converted_call(ag__.ld(value).numpy, (), None, fscope):.6f}
AttributeError: in user code:

    File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 39, in quaternion_angle_loss  *
        save_values_with_labels_to_txt(rotation_loss_file, "y_true", y_true)
    File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 21, in save_values_with_labels_to_txt  *
        f.write(f"{value.numpy():.6f}\n")

    AttributeError: 'Tensor' object has no attribute 'numpy'

/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 98, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 28, in call
    x_dct = self._dct3D(inputs)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 40, in _dct3D
    tf.transpose(tf.signal.dct(x_perm, 2, norm='ortho'), perm=[0, 1, 2, 4, 3]),
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Exception encountered when calling layer 'dct_pooling3d' (type DCTPooling3D).

{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[2957312,76] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Pad]

Call arguments received by layer 'dct_pooling3d' (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(64, 38, 38, 38, 32), dtype=float32)
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 32 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 98, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 28, in call
    x_dct = self._dct3D(inputs)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/DCTPooling3D.py", line 39, in _dct3D
    output = tf.transpose(tf.signal.dct(tf.transpose(tf.signal.dct(
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Exception encountered when calling layer 'dct_pooling3d_5' (type DCTPooling3D).

{{function_node __wrapped__RFFT_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,64,24,24,25] and type complex64 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RFFT]

Call arguments received by layer 'dct_pooling3d_5' (type DCTPooling3D):
  • inputs=tf.Tensor(shape=(32, 24, 24, 24, 64), dtype=float32)
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 32 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 128, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 115, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 98, in train_pcrnet_continue
    history = model.fit(train_data, validation_data=test_data, epochs=epochs, steps_per_epoch=steps_per_epoch,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filezgeou4pt.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/tmp/__autograph_generated_file5qrzpvl5.py", line 10, in tf__quaternion_angle_loss
    ag__.converted_call(ag__.ld(save_values_with_labels_to_txt), (ag__.ld(rotation_loss_file), 'y_true', ag__.ld(y_true)), None, fscope)
  File "/tmp/__autograph_generated_filejk69r__w.py", line 23, in tf__save_values_with_labels_to_txt
    ag__.for_stmt(ag__.ld(values), None, loop_body, get_state, set_state, (), {'iterate_names': 'value'})
  File "/tmp/__autograph_generated_filejk69r__w.py", line 20, in loop_body
    ag__.converted_call(ag__.ld(f).write, (f'''{ag__.converted_call(ag__.ld(value).numpy, (), None, fscope):.6f}
AttributeError: in user code:

    File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/engine/training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 38, in quaternion_angle_loss  *
        save_values_with_labels_to_txt(rotation_loss_file, "y_true", y_true)
    File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py", line 20, in save_values_with_labels_to_txt  *
        f.write(f"{value.numpy():.6f}\n")

    AttributeError: 'Tensor' object has no attribute 'numpy'

/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72--pretrained_model /HBV/Caohaofan/results-1/model_iter11.h5
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 33, in run
    args = run_whole(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 169, in run_whole
    args.steps_per_epoch = int(int(args.select_subtomo_number) * 6 * 12 / args.batch_size)
ValueError: invalid literal for int() with base 10: '72--pretrained_model'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72 --pretrained_model /HBV/Caohaofan/results-1/model_iter11.h5
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 80, in run
    predict(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/predict.py", line 32, in predict
    temple_data = get_mrc_data(temple_mrc_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/img_processing.py", line 15, in get_mrc_data
    with mrcfile.open(mrc_path, permissive=True) as cdata:
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/load_functions.py", line 139, in open
    return NewMrc(name, mode=mode, permissive=permissive,
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 109, in __init__
    self._open_file(name)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/mrcfile/mrcfile.py", line 126, in _open_file
    self._iostream = open(name, self._mode + 'b')
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results/tmp_0.mrc'
/HBV/Caohaofan/selfalign/SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72 --pretrained_model /HBV/Caohaofan/results-1/model_iter11.h5
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 100 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results --rota /HBV/Caohaofan/rota --preprocessing_ncpus 22 --select_subtomo_number 72
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 47, in run
    from SelfAlign.models.pcrnet.predict import predict
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/predict.py", line 12, in <module>
    from SelfAlign.models.pcrnet.tf_util_loss import quaternion_angle_loss, translation_loss
ImportError: cannot import name 'quaternion_angle_loss' from 'SelfAlign.models.pcrnet.tf_util_loss' (/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py)
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 47, in run
    from SelfAlign.models.pcrnet.predict import predict
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/predict.py", line 12, in <module>
    from SelfAlign.models.pcrnet.tf_util_loss import quaternion_angle_loss, translation_loss
ImportError: cannot import name 'quaternion_angle_loss' from 'SelfAlign.models.pcrnet.tf_util_loss' (/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py)
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 48, in run
    from SelfAlign.models.pcrnet.train import prepare_first_model, train_pcrnet
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 12, in <module>
    from SelfAlign.models.pcrnet.tf_util_loss import quaternion_angle_loss, translation_loss, correlation_coefficient_loss
ImportError: cannot import name 'quaternion_angle_loss' from 'SelfAlign.models.pcrnet.tf_util_loss' (/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/tf_util_loss.py)
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_degree30 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 125, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 22
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 125, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 125, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 125, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/pcrnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 100, in prepare_custom_dataseq
    train_records = read_non_empty_lines(train_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/train/train_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 114, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 96, in train_pcrnet_continue
    train_data, test_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    test_records = read_non_empty_lines(test_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/test/test_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 115, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 115, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 115, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 115, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 1024 --preprocessing_ncpus 22
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 48, in get_cubes
    w = np.cos(theta / 2) * np.cos(phi / 2)
NameError: name 'theta' is not defined
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 114, in run
    get_cubes_list(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 107, in get_cubes_list
    p.map(func, inp)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
NameError: name 'theta' is not defined
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 1024 --preprocessing_ncpus 22
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 67, in get_cubes
    quaternion = inverse_rotation_obj.as_quat(canonical=True)
TypeError: as_quat() takes no keyword arguments
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 114, in run
    get_cubes_list(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/preprocessing/prepare.py", line 107, in get_cubes_list
    p.map(func, inp)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
TypeError: as_quat() takes no keyword arguments
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 1024 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 128 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 128 --preprocessing_ncpus 22
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 120, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 102, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --select_subtomo_number 128 --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 65, in run
    args.mrc_list = np.random.choice(args.all_mrc_list, size=int(args.select_subtomo_number), replace=False)
  File "mtrand.pyx", line 965, in numpy.random.mtrand.RandomState.choice
ValueError: Cannot take a larger sample than population when 'replace=False'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 40 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /HBV/Caohaofan/simulation_euler --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /newdata2/chf/simulation_5LQW --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 47, in run
    from SelfAlign.models.gumnet.predict import predict
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/predict.py", line 20, in <module>
    tf.config.set_visible_devices(gpus[1], 'GPU')
IndexError: list index out of range
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /newdata2/chf/simulation_5LQW --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 48, in run
    from SelfAlign.models.gumnet.train import prepare_first_model, train_pcrnet
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 19, in <module>
    tf.config.set_visible_devices(gpus[1], 'GPU')
IndexError: list index out of range
./SelfAlign/bin/selfalign.py refine --subtomo_star subtomo.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_smi --rota /newdata2/chf/simulation_5LQW --preprocessing_ncpus 1
./SelfAlign/bin/selfalign.py refine --subtomo_star 5MPA.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_5MPA --rota /newdata2/chf/simulation_5MPA --preprocessing_ncpus 1
./SelfAlign/bin/selfalign.py refine --subtomo_star 5T2C.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_5T2C --rota /newdata2/chf/simulation_5T2C --preprocessing_ncpus 1
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /HBV/Caohaofan/results_6A5L --rota /newdata2/chf/simulation_6A5L --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_smi/data/valid/valid_1.txt'
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_5MPA/data/valid/valid_1.txt'
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_5T2C/data/valid/valid_1.txt'
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/HBV/Caohaofan/results_6A5L/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star 5LQW.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata2/chf/test_data/5LQW --rota /newdata2/chf/test_data/rota/5LQW --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/newdata2/chf/test_data/5LQW/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star 5MPA.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata2/chf/test_data/5MPA --rota /newdata2/chf/test_data/rota/5MPA --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/newdata2/chf/test_data/5MPA/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star 5T2C.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata2/chf/test_data/5T2C --rota /newdata2/chf/test_data/rota/5T2C --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/newdata2/chf/test_data/5T2C/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata2/chf/test_data/6A5L --rota /newdata2/chf/test_data/rota/6A5L --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 120, in run
    history = train_pcrnet(args)  # train based on init model and save new one as model_iter{num_iter}.h5
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 58, in train_pcrnet
    history = train_pcrnet_continue(
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 40, in train_pcrnet_continue
    train_data, valid_data = prepare_custom_dataseq(data_dir, batch_size, iter_count)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 101, in prepare_custom_dataseq
    valid_records = read_non_empty_lines(valid_txt_path)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/data_sequence.py", line 113, in read_non_empty_lines
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/newdata2/chf/test_data/6A5L/data/valid/valid_1.txt'
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata3/chf/test_data2/6A5L --rota /newdata3/chf/test_data2/rota/6A5L --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 97, in run
    prepare_first_model(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 51, in prepare_first_model
    model = get_model(input_shape)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/Gum_Net.py", line 96, in get_model
    c_ab = Conv3D(1024, (3, 3, 3))(c_ab)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/backend.py", line 2101, in random_uniform
    return tf.random.stateless_uniform(
tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata3/chf/test_data2/6A5L --rota /newdata3/chf/test_data2/rota/6A5L --preprocessing_ncpus 1
Traceback (most recent call last):
  File "/HBV/Caohaofan/selfalign/SelfAlign/bin/refine.py", line 97, in run
    prepare_first_model(args)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/train.py", line 51, in prepare_first_model
    model = get_model(input_shape)
  File "/HBV/Caohaofan/selfalign/SelfAlign/models/gumnet/Gum_Net.py", line 96, in get_model
    c_ab = Conv3D(1024, (3, 3, 3))(c_ab)
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ubuntu/.conda/envs/align/lib/python3.8/site-packages/keras/backend.py", line 2101, in random_uniform
    return tf.random.stateless_uniform(
tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 64 --result_dir /newdata3/chf/test_data2/6A5L --rota /newdata3/chf/test_data2/rota/6A5L --preprocessing_ncpus 1
./SelfAlign/bin/selfalign.py refine --subtomo_star 6A5L.star --epochs 1 --iterations 1 --subtomo_size 32 --gpuID 1 --batch_size 1 --result_dir /newdata3/chf/test_data2/6A5L --rota /newdata3/chf/test_data2/rota/6A5L --preprocessing_ncpus 1
